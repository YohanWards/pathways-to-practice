n = 1
} else {
n = 2
}
trial.idxs = apply(task.idxs, 2, sample, n)
# if an even trial, add a coincidental stimulus
if (i%%2 == 0) trial.idxs = rbind(trial.idxs, rep(sample(irrel.idxs, 1), times=n.task))
trial.idxs = as.vector(trial.idxs)
# encoded stimulu
stim.encoded = stim.mat[,trial.idxs] + generate.noise(n.features, length(trial.idxs))
stim.encoded = apply(stim.encoded, 2, norm.vec.lngth)
distance = apply(stim.encoded, 2, function(x) apply(stim.mat, 2, calc.euclid, y = x))
similarity = 1/distance
# update priors (from 1st half of sim mat columns for task A, second half for task B)
if (n.task == 2 & i%%2 != 0 & stim.overlap == "none"){
task.a.priors = task.a.priors + (learn.rate * similarity[,1])
task.b.priors = task.b.priors + (learn.rate * similarity[,2])
} else {
task.a.priors = task.a.priors + (learn.rate * apply(similarity[,1:(length(trial.idxs)/2)], 1, sum ))
task.b.priors = task.b.priors + (learn.rate * apply(similarity[,((length(trial.idxs)/2)+1):length(trial.idxs)], 1, sum ))
}
#   prior.dat$task.A[prior.dat$trial==i] = task.a.priors
#   prior.dat$task.B[prior.dat$trial==i] = task.b.priors
kl.dat$KL[i] = get.KL(task.b.priors, task.a.priors)
kl.dat$interference.T[i] = 1/kl.dat$KL[i]
}
kl.dat
}
n.stim = 10
n.task = 2
n.features = 10 # randomly chosen
n.practice.trials = 15
priors = rep(1, times=(n.stim*n.task)+n.stim) # priors over each the task space (to define Dirichlet distribution)
learn.rate = 0.01 # a weighting for new observations
cov.rngs = list(lo=c(-1, 1),hi=c(9, 11))
cov.fact=c("lo", "hi")
n.vars = length(cov.rngs)
n.sims = 1000 # number of simulations to perform
cov.mat = lapply(cov.rngs, gen.cov.mat, n.stim=(n.stim*n.task)+n.stim) # generate a covariance matrix from which to generate random, correlated vectors that is n = total stim across tasks, plus n.stim number of coincidental stimuli
cov.mat = lapply(cov.mat, make.positive.definite, tol=1e-3) # using this to make matrix positive definite, on account of advice from https://stackoverflow.com/questions/27176595/error-sigma-must-be-positive-definite/27179588
# if required, make positive definite
s.mat = lapply(cov.mat, mvrnorm, n=n.features, mu=rep(0, times=(n.stim*n.task)+n.stim))
# check the stim.mat covariance matrix is similar to the input one
check = cov(s.mat$lo) # visual check is comforting
# now normalise the vectors to unit length (for using distance measure below)
s.mat = lapply(s.mat, function(x) apply(x, 2, norm.vec.lngth))
# first, generate the stimulus based on one of the existing stimulus vectors, add noise
this.stim.idx = sample(1:n.stim*n.task, 1) # which stimulus is presented?
stim.encoded = s.mat$hi[,this.stim.idx] + rnorm(n.features, mean=0, sd=.1)
stim.encoded = norm.vec.lngth(stim.encoded)
distance = apply(s.mat$hi, 2, calc.euclid, y = stim.encoded)
similarity = 1/distance
kl.dat = replicate(n.sims, mapply(stim.mat=s.mat, cov.fact=cov.fact, run.sim, MoreArgs=list(n.stim=n.stim, n.task=n.task, n.vars=n.vars, n.practice.trials=n.practice.trials, priors=priors, n.features=n.features, learn.rate=learn.rate, stim.overlap = "none"), SIMPLIFY=FALSE))
kl.dat = do.call(rbind, kl.dat)
kl.dat = kl.dat %>% group_by(covar, trial) %>%
summarise(multicost = mean(interference.T),
se=sd(interference.T)/sqrt(length(interference.T)))
kl.dat
kl.dat %>%
ggplot(aes(trial, multicost, color=covar, group=covar)) +
geom_line(size=1) +
scale_color_manual(values=wesanderson::wes_palette("IsleofDogs1")[c(1:2)]) +
scale_fill_manual(values=wesanderson::wes_palette("IsleofDogs1")[c(1:2)]) +
geom_ribbon(aes(ymin=multicost-(1.96*se), ymax=multicost+(1.96*se)), alpha=0.3, colour=NA) +
ylim(10, 4000) + # a range that is typical across all sims
theme_classic() +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks.y = element_blank()) +
labs(colour = "Covariance",
x = "trials [au]",
y = "multitasking cost [au]")
kl.dat %>%
ggplot(aes(trial, multicost, color=covar, group=covar)) +
geom_line(size=1) +
scale_color_manual(values=wesanderson::wes_palette("IsleofDogs1")[c(1:2)]) +
scale_fill_manual(values=wesanderson::wes_palette("IsleofDogs1")[c(1:2)]) +
geom_ribbon(aes(ymin=multicost-(1.96*se), ymax=multicost+(1.96*se)), alpha=0.3, colour=NA) +
ylim(10, 6000) + # a range that is typical across all sims
theme_classic() +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks.y = element_blank()) +
labs(colour = "Covariance",
x = "trials [au]",
y = "multitasking cost [au]")
kl.dat %>%
ggplot(aes(trial, multicost, color=covar, group=covar)) +
geom_line(size=1) +
scale_color_manual(values=wesanderson::wes_palette("IsleofDogs1")[c(1:2)]) +
scale_fill_manual(values=wesanderson::wes_palette("IsleofDogs1")[c(1:2)]) +
geom_ribbon(aes(ymin=multicost-(1.96*se), ymax=multicost+(1.96*se)), alpha=0.3, colour=NA) +
ylim(10, 5000) + # a range that is typical across all sims
theme_classic() +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks.y = element_blank()) +
labs(colour = "Covariance",
x = "trials [au]",
y = "multitasking cost [au]")
overlap.dat = replicate(n.sims, mapply(stim.mat=s.mat, cov.fact=cov.fact, run.sim, MoreArgs=list(n.stim=n.stim, n.task=n.task,
n.vars=n.vars, n.practice.trials=n.practice.trials, priors=priors, n.features=n.features,
learn.rate=learn.rate, stim.overlap = "low"), SIMPLIFY=FALSE))
overlap.dat = do.call(rbind, overlap.dat)
overlap.dat$overlap = "low"
nu.dat = replicate(n.sims, mapply(stim.mat=s.mat, cov.fact=cov.fact, run.sim, MoreArgs=list(n.stim=n.stim, n.task=n.task,
n.vars=n.vars, n.practice.trials=n.practice.trials, priors=priors, n.features=n.features,
learn.rate=learn.rate, stim.overlap = "high"), SIMPLIFY=FALSE))
nu.dat = do.call(rbind, nu.dat)
nu.dat$overlap = "high"
overlap.dat = rbind(overlap.dat, nu.dat)
rm(nu.dat)
overlap.dat$overlap <- as.factor(overlap.dat$overlap)
levels(overlap.dat$overlap) = c("low", "high")
overlap.dat = overlap.dat %>% group_by(overlap, covar, trial) %>%
summarise(multicost = mean(interference.T),
se=sd(interference.T)/sqrt(length(interference.T)))
overlap.dat %>%
ggplot(aes(trial, multicost, color=covar, group=covar)) +
geom_line(size=1.5) +
ylim(10, 5000) +
scale_color_manual(values=wesanderson::wes_palette("IsleofDogs1")[c(1:2)]) +
scale_fill_manual(values=wesanderson::wes_palette("IsleofDogs1")[c(1:2)]) +
geom_ribbon(aes(ymin=multicost-(1.96*se), ymax=multicost+(1.96*se)), alpha=0.4, colour=NA) +
facet_wrap(~ overlap) +
theme_classic() +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks.y = element_blank()) +
labs(colour = "Covariance",
x = "trials [au]",
y = "multitasking cost [au]")
rm(list=ls())
library(tidyverse)
library(rmarkdown)    # You need this library to run this template.
library(epuRate)      # Install with devtools: install_github("holtzy/epuRate", force=TRUE)
library(MASS)
library(corpcor)
library(wesanderson)
gen.cov.mat <- function(n.stim, cov.rng){
# generates covariance matrix to initialise vectors
# output = mat (an n.stim x n.stim covariance matrix)
# inputs =
# n.stim - the number of stimuli, covariance matrix will be n x n
# cor.rng = lower and upper bound of task covariances
mat = diag(x=1, n.stim, n.stim)
cor.rng <- runif(length(mat[lower.tri(mat)]), min(cov.rng), max(cov.rng))
mat[lower.tri(mat)] = cor.rng
mat = t(mat)
mat[lower.tri(mat)] = cor.rng
mat
}
norm.vec.lngth <- function(v){
# this function takes a vector and returns the unit vector
mu = 1/ sqrt( t(v) %*% v ) # first is transferred as inputs are interpreted as row vectors
v = mu * v
v
}
calc.euclid <- function(x,y){
# compute the euclidean distance between two vectors
sqrt( sum( (x-y) ^ 2 )  )
}
rdirichlet<-function (n, alpha) {
# I got this function from:
# https://stats.stackexchange.com/questions/166289/generate-data-from-dirichlet-distribution - also see page 585 of Gelman's BDA, 3r ed.
l <- length(alpha)
x <- matrix(rgamma(l * n, alpha), ncol = l, byrow = TRUE) # generate n observations using the gamma function, given l alpha paramaters, and n observations
sm <- x %*% rep(1, l) # sum each row of the matrix
x/as.vector(sm)
}
get.KL <- function(alpha, beta){
# find out how well the dirichlet distribution defined by alpha is approximated by the dirichlet distribution defined by the beta parameters. Computes the KL divergence using the derivation at:
# http://bariskurt.com/kullback-leibler-divergence-between-two-dirichlet-and-beta-distributions/
lgamma(sum(alpha)) - lgamma(sum(beta)) - sum(lgamma(alpha)) + sum(lgamma(beta)) + sum((alpha - beta)*(digamma(alpha)-digamma(sum(beta))))
}
# get.interference <- function(p){
#   # implement Hick-Hyman's law for a decision involving 2 events, p = p of event 1
#   sum(  p * log2( (1/p) + 1 ),  (1-p) * log2( (1/( 1- p)) + 1   ) )
# }
generate.noise <- function(n.feat, n.stim){
# n.feat = the number of features that require noise assigned to them
# n.stim = the total number of stimuli sampled across the two tasks
# mat.dims = the dimensions of the n x p internal stimulus matrix
# output is a matrix of noise to be added to the stimuli encoded matrix
matrix(rnorm(n.feat*n.stim, mean=0, sd=.1), nrow=n.feat)
}
run.sim <- function(n.stim, n.task, n.vars, n.practice.trials, priors, stim.mat, n.features, learn.rate, cov.fact, stim.overlap){
# initialise dataframe to collect behavioural results
kl.dat = data.frame(covar=factor(rep(cov.fact, each=n.practice.trials)),
trial=factor(c(1:n.practice.trials)),
KL=rep(NA, times=n.practice.trials),
interference.T=rep(NA, times=n.practice.trials))
task.a.priors = priors # initialise task A model parameters
task.b.priors = priors  # same for task B
# set the range of values to sample stimuli from for each task
irrel.idxs = ((n.task*n.stim)+1):ncol(stim.mat)
task.idxs = matrix(c(1:(n.stim*n.task)), byrow=FALSE, nrow=n.stim)
if (stim.overlap == "low") {
task.idxs[sample(1:nrow(task.idxs), 5),1] = task.idxs[sample(1:nrow(task.idxs), 5), 2]
} else if (stim.overlap == "high") {
task.idxs[,1] = task.idxs[, 2]
}
# now run the simulation
for (i in 1:n.practice.trials){
# step 1: select stimuli from the set of task A, from the set of task B, and if an even trial, from the set of task C
if (stim.overlap == "none"){
n = 1
} else {
n = 2
}
trial.idxs = apply(task.idxs, 2, sample, n)
# if an even trial, add a coincidental stimulus
if (i%%2 == 0) trial.idxs = rbind(trial.idxs, rep(sample(irrel.idxs, 1), times=n.task))
trial.idxs = as.vector(trial.idxs)
# encoded stimulu
stim.encoded = stim.mat[,trial.idxs] + generate.noise(n.features, length(trial.idxs))
stim.encoded = apply(stim.encoded, 2, norm.vec.lngth)
distance = apply(stim.encoded, 2, function(x) apply(stim.mat, 2, calc.euclid, y = x))
similarity = 1/distance
# update priors (from 1st half of sim mat columns for task A, second half for task B)
if (n.task == 2 & i%%2 != 0 & stim.overlap == "none"){
task.a.priors = task.a.priors + (learn.rate * similarity[,1])
task.b.priors = task.b.priors + (learn.rate * similarity[,2])
} else {
task.a.priors = task.a.priors + (learn.rate * apply(similarity[,1:(length(trial.idxs)/2)], 1, sum ))
task.b.priors = task.b.priors + (learn.rate * apply(similarity[,((length(trial.idxs)/2)+1):length(trial.idxs)], 1, sum ))
}
#   prior.dat$task.A[prior.dat$trial==i] = task.a.priors
#   prior.dat$task.B[prior.dat$trial==i] = task.b.priors
kl.dat$KL[i] = get.KL(task.b.priors, task.a.priors)
kl.dat$interference.T[i] = 1/kl.dat$KL[i]
}
kl.dat
}
n.stim = 10
n.task = 2
n.features = 10 # randomly chosen
n.practice.trials = 10
priors = rep(1, times=(n.stim*n.task)+n.stim) # priors over each the task space (to define Dirichlet distribution)
learn.rate = 0.01 # a weighting for new observations
cov.rngs = list(lo=c(-1, 1),hi=c(9, 11))
cov.fact=c("lo", "hi")
n.vars = length(cov.rngs)
n.sims = 1000 # number of simulations to perform
cov.mat = lapply(cov.rngs, gen.cov.mat, n.stim=(n.stim*n.task)+n.stim) # generate a covariance matrix from which to generate random, correlated vectors that is n = total stim across tasks, plus n.stim number of coincidental stimuli
cov.mat = lapply(cov.mat, make.positive.definite, tol=1e-3) # using this to make matrix positive definite, on account of advice from https://stackoverflow.com/questions/27176595/error-sigma-must-be-positive-definite/27179588
# if required, make positive definite
s.mat = lapply(cov.mat, mvrnorm, n=n.features, mu=rep(0, times=(n.stim*n.task)+n.stim))
# check the stim.mat covariance matrix is similar to the input one
check = cov(s.mat$lo) # visual check is comforting
# now normalise the vectors to unit length (for using distance measure below)
s.mat = lapply(s.mat, function(x) apply(x, 2, norm.vec.lngth))
# first, generate the stimulus based on one of the existing stimulus vectors, add noise
this.stim.idx = sample(1:n.stim*n.task, 1) # which stimulus is presented?
stim.encoded = s.mat$hi[,this.stim.idx] + rnorm(n.features, mean=0, sd=.1)
stim.encoded = norm.vec.lngth(stim.encoded)
distance = apply(s.mat$hi, 2, calc.euclid, y = stim.encoded)
similarity = 1/distance
kl.dat = replicate(n.sims, mapply(stim.mat=s.mat, cov.fact=cov.fact, run.sim, MoreArgs=list(n.stim=n.stim, n.task=n.task, n.vars=n.vars, n.practice.trials=n.practice.trials, priors=priors, n.features=n.features, learn.rate=learn.rate, stim.overlap = "none"), SIMPLIFY=FALSE))
kl.dat = do.call(rbind, kl.dat)
kl.dat = kl.dat %>% group_by(covar, trial) %>%
summarise(multicost = mean(interference.T),
se=sd(interference.T)/sqrt(length(interference.T)))
kl.dat %>%
ggplot(aes(trial, multicost, color=covar, group=covar)) +
geom_line(size=1) +
scale_color_manual(values=wesanderson::wes_palette("IsleofDogs1")[c(1:2)]) +
scale_fill_manual(values=wesanderson::wes_palette("IsleofDogs1")[c(1:2)]) +
geom_ribbon(aes(ymin=multicost-(1.96*se), ymax=multicost+(1.96*se)), alpha=0.3, colour=NA) +
ylim(10, 5000) + # a range that is typical across all sims
theme_classic() +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks.y = element_blank()) +
labs(colour = "Covariance",
x = "trials [au]",
y = "multitasking cost [au]")
kl.dat %>%
ggplot(aes(trial, multicost, color=covar, group=covar)) +
geom_line(size=1) +
scale_color_manual(values=wesanderson::wes_palette("IsleofDogs1")[c(1:2)]) +
scale_fill_manual(values=wesanderson::wes_palette("IsleofDogs1")[c(1:2)]) +
geom_ribbon(aes(ymin=multicost-(1.96*se), ymax=multicost+(1.96*se)), alpha=0.3, colour=NA) +
ylim(10, 6000) + # a range that is typical across all sims
theme_classic() +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks.y = element_blank()) +
labs(colour = "Covariance",
x = "trials [au]",
y = "multitasking cost [au]")
overlap.dat = replicate(n.sims, mapply(stim.mat=s.mat, cov.fact=cov.fact, run.sim, MoreArgs=list(n.stim=n.stim, n.task=n.task,
n.vars=n.vars, n.practice.trials=n.practice.trials, priors=priors, n.features=n.features,
learn.rate=learn.rate, stim.overlap = "low"), SIMPLIFY=FALSE))
overlap.dat = do.call(rbind, overlap.dat)
overlap.dat$overlap = "low"
nu.dat = replicate(n.sims, mapply(stim.mat=s.mat, cov.fact=cov.fact, run.sim, MoreArgs=list(n.stim=n.stim, n.task=n.task,
n.vars=n.vars, n.practice.trials=n.practice.trials, priors=priors, n.features=n.features,
learn.rate=learn.rate, stim.overlap = "high"), SIMPLIFY=FALSE))
nu.dat = do.call(rbind, nu.dat)
nu.dat$overlap = "high"
overlap.dat = rbind(overlap.dat, nu.dat)
rm(nu.dat)
overlap.dat$overlap <- as.factor(overlap.dat$overlap)
levels(overlap.dat$overlap) = c("low", "high")
overlap.dat = overlap.dat %>% group_by(overlap, covar, trial) %>%
summarise(multicost = mean(interference.T),
se=sd(interference.T)/sqrt(length(interference.T)))
overlap.dat %>%
ggplot(aes(trial, multicost, color=covar, group=covar)) +
geom_line(size=1.5) +
ylim(10, 6000) +
scale_color_manual(values=wesanderson::wes_palette("IsleofDogs1")[c(1:2)]) +
scale_fill_manual(values=wesanderson::wes_palette("IsleofDogs1")[c(1:2)]) +
geom_ribbon(aes(ymin=multicost-(1.96*se), ymax=multicost+(1.96*se)), alpha=0.4, colour=NA) +
facet_wrap(~ overlap) +
theme_classic() +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks.y = element_blank()) +
labs(colour = "Covariance",
x = "trials [au]",
y = "multitasking cost [au]")
warnings()
kl.dat %>%
ggplot(aes(trial, multicost, color=covar, group=covar)) +
geom_line(size=1) +
scale_color_manual(values=wesanderson::wes_palette("IsleofDogs1")[c(1:2)]) +
scale_fill_manual(values=wesanderson::wes_palette("IsleofDogs1")[c(1:2)]) +
geom_ribbon(aes(ymin=multicost-(1.96*se), ymax=multicost+(1.96*se)), alpha=0.3, colour=NA) +
ylim(10, 6500) + # a range that is typical across all sims
theme_classic() +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks.y = element_blank()) +
labs(colour = "Covariance",
x = "trials [au]",
y = "multitasking cost [au]")
randperm(3)
sample(3)
sample(3,1)
setwd("~/Dropbox/QBI/pathways-to-practice")
rm(list=ls())
# this function will pull out the FA measures from the participant
# level FA matrices
# the function assumes that within the folder defined by fpath, the data
# are in two subfolders called 'group-control' and 'group-practice'
results = list()
fpath = '~/Dropbox/QBI/pathways-to-practice/dti-data'
fpath = '~/Dropbox/QBI/pathways-to-practice/dti-data/'
list.files(paste(fpath, 'group-practice', seup=""), pattern="FA")
list.files(paste(fpath, 'group-practice', sep=""), pattern="FA")
sub_fols = c('group-practice', 'group-control')
fnames = sapply(sub_fols, function(x) list.files(paste(fpath, x, sep=""), pattern="FA") )
fnames <- do.call(rbind, fnames)
fnames
fnames <- lapply(sub_fols, function(x) list.files(paste(fpath, x, sep=""), pattern="FA") )
fnames <- do.call(rbind, fnames)
fnames <- lapply(sub_fols, function(x) list.files(paste(fpath, x, sep=""), pattern="FA") )
fnames <- do.call(cbind, fnames)
fnames
fnames <- lapply(sub_fols, function(x) list.files(paste(fpath, x, sep=""), pattern="FA") )
fnames <- c(do.call(cbind, fnames) )
f = fnames[1]
f
f[2]
f = fnames[1]
f
strsplit(f, "_")
strsplit(f, "_")[2]
strsplit(f, "_")[[1]][2]
strtoi(strsplit(f, "_")[[1]][2])
sub.num <- strtoi(strsplit(f, "_")[[1]][2])
if (sub.num < 2000) {
group = 1
} else {
group = 2
}
group = 1
sub.num
round(sub.num*.1)
sub.num = 2012
round(sub.num*.1)
sub.num <- round(sub.num.full*.1)
f <- fnames[1]
sub.num.full <- strtoi(strsplit(f, "_")[[1]][2])
if (sub.num.full < 2000) {
group = 1
} else {
group = 2
}
sub.num <- round(sub.num.full*.1)
group
sub.num
sub.num %/% 2
sub.num mod 2
2 %/% sub.num
2 %/% sub.num.full
sub.num.full = 1012
2 %/% sub.num.full
mod(sub.num.full, 2)
2 %% sub.num.full
sub.num.full = 1011
2 %% sub.num.full
2 %/% sub.num.full
2 mod sub.num.full
sub.num.full
8 %/% 2
8 %% 2
1011 %% 2
1012 %% 2
pre.post <- sub.num.full %% 2
f <- fnames[1]
sub.num.full <- strtoi(strsplit(f, "_")[[1]][2])
if (sub.num.full < 2000) {
group = 1
} else {
group = 2
}
sub.num <- round(sub.num.full*.1)
pre.post <- sub.num.full %% 2
pre.post
pre.post <- 1-(sub.num.full %% 2)
f
tmp.dat <- read.table(paste(fpath, f, sep=""))  # ,header=FALSE)
tmp.dat <- read.table(paste(fpath, sub_fols[group], sep=""))  # ,header=FALSE)
paste(fpath, sub_fols[group], sep="")
tmp.dat <- read.table(paste(fpath, sub_fols[group], '/', f, sep=""))  # ,header=FALSE)
View(tmp.dat)
tmp.dat <- read.table(paste(fpath, sub_fols[group], '/', f, sep="") ,header=FALSE)
tmp.dat
View(tmp.dat)
labels <- read.table(paste(fpath, '/', 'aal_labels.txt')
)
labels <- read.table(paste(fpath, 'aal_labels.txt', sep=""))
labels
labels <- read.table(paste(fpath, 'aal_labels.txt', sep=""), header = FALSE)
tracts = list(c("Precentral_gyrus_Left", "Middle_Frontal_gyrus_Left"),
c("Supplementary_motor_area_Left", "Rolandic_Operculum_Left"))
tracts
tracts[[1]] %in% labels
labels %in% tracts[[1]]
match(tracts[[1]], labels)
labels
t(labels)
match(tracts[[1]], t(labels))
lapply(tracts, function(x) match(x, labels))
lapply(tracts, function(x) match(x, t(labels)))
tract.idxs = lapply(tracts, function(x) match(x, t(labels)))
tract.idxs
tmp.dat[tract.idxs[[1]][1], tract.idxs[[1]][2]]
head(tmp.dat)
lapply(tract.idxs, function(x) tmp.dat[x[1],x[2]])
sapply(tract.idxs, function(x) tmp.dat[x[1],x[2]])
sapply(tracts, function(x) x[1])
tracts
# now, for each file, pull out the required data
GetSubData <- function(f, tracts){
sub.num.full <- strtoi(strsplit(f, "_")[[1]][2])
if (sub.num.full < 2000) {
group = 1
} else {
group = 2
}
sub.num <- round(sub.num.full*.1)
pre.post <- 1-(sub.num.full %% 2)
tmp.dat <- read.table(paste(fpath, sub_fols[group], '/', f, sep="") ,header=FALSE)
labels <- read.table(paste(fpath, 'aal_labels.txt', sep=""), header = FALSE)
tract.idxs <- lapply(tracts, function(x) match(x, t(labels)))
FA.vals <- sapply(tract.idxs, function(x) tmp.dat[x[1],x[2]])
N = length(FA.vals)
sub.data <- data.frame(sub = rep(sub.num, each=N),
group = rep(group, each=N),
session = rep(pre.post, each=N),
tract_start = sapply(tracts, function(x) x[1]),
tract_end = sapply(tracts, function(x) x[2]),
FA = FA.vals)
sub.data
}
sub.data <- lapply(fnames, GetSubData, tracts = tracts)
sub.data <- do.call(rbind, sub.data)
View(sub.data)
rm(list=ls())
# load packages and source data-wrangling functions
# --------------------------------------------------------------------------------
# install.packages("tidyverse")  # uncomment and run if you don't have tidyverse
# installed already
library(tidyverse)
source("KG_data-wrangling.R")
rm(list=ls())
# set working directory to current location
# install.packages("rstudioapi")  # uncomment and run if you don't already have this package installed
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory to the location of this file
# load packages and source data-wrangling functions
# --------------------------------------------------------------------------------
# install.packages("tidyverse")  # uncomment and run if you don't have tidyverse
# installed already
library(tidyverse)
source("KG_data-wrangling.R")
fpath <- '~/Dropbox/QBI/pathways-to-practice/dti-data/' # filepath to where the data lives
tracts = list(c("Precentral_gyrus_Left", "Middle_Frontal_gyrus_Left"),
c("Supplementary_motor_area_Left", "Rolandic_Operculum_Left"))
sub.data <- GetDTIData(fpath, tracts)
source("R_rainclouds.R")
